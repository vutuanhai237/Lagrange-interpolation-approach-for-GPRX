{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.012383417820756418-8.673617379884035e-18j)\n"
     ]
    }
   ],
   "source": [
    "import tqix, qiskit\n",
    "import numpy as np\n",
    "\n",
    "def H_LMG(h, lambdax, n, Jx, Jy, Jz):\n",
    "    return -2*h*Jz - 2*lambdax/n*(Jx**2 - Jy**2)\n",
    "\n",
    "def get_psi(thetas, n):\n",
    "    qc = qiskit.QuantumCircuit(n)\n",
    "    for i in range(0, n, 3):\n",
    "        qc.rx(thetas[i], 0)\n",
    "        qc.rz(thetas[i + 1], 1)\n",
    "        qc.rx(thetas[i + 2], 2)\n",
    "    return qiskit.quantum_info.Statevector.from_instruction(qc).data\n",
    "n = 5\n",
    "lambdax = 0.05\n",
    "hs = [-0.1, 0, 0.1]\n",
    "thetas = np.ones(n*3)\n",
    "thetas[2] = np.pi/3\n",
    "qc = tqix.circuit(n)\n",
    "for i in range(0, n, 3):\n",
    "    qc.RX(thetas[i], 0)\n",
    "    qc.RZ(thetas[i + 1], 1)\n",
    "    qc.RX(thetas[i + 2], 2)\n",
    "    \n",
    "Jx = qc.Jx()\n",
    "Jy = qc.Jy()\n",
    "Jz = qc.Jz()\n",
    "\n",
    "h_LMG = H_LMG(hs[0], lambdax, n, Jx, Jy, Jz)\n",
    "psi = qc.state\n",
    "print(np.trace((h_LMG @ psi).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9644759 , 5.17531829, 2.70746915, 0.34326549, 4.22412149,\n",
       "       5.59371018, 4.84429238, 1.80126693, 4.56341304, 5.23205335,\n",
       "       5.8469486 , 5.50293912, 4.16056373, 2.72112783, 3.12698443])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(0, 2*np.pi, (3*n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\haime\\OneDrive\\Documents\\GitHub\\Lagrange interpolation approach for GPRX\\tqix_compare.ipynb Cell 3\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_dict, time_iters\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m optimizer \u001b[39m=\u001b[39m GD(lr\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m, eps\u001b[39m=\u001b[39m\u001b[39m1e-10\u001b[39m, maxiter\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m, tol\u001b[39m=\u001b[39m\u001b[39m1e-19\u001b[39m, N\u001b[39m=\u001b[39mn)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m loss_dict, _ \u001b[39m=\u001b[39m tensor(optimizer, loss_dict, \u001b[39m\"\u001b[39;49m\u001b[39mtensor_gd\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\haime\\OneDrive\\Documents\\GitHub\\Lagrange interpolation approach for GPRX\\tqix_compare.ipynb Cell 3\u001b[0m in \u001b[0;36mtensor\u001b[1;34m(optimizer, loss_dict, mode)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m objective_function \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m params: cost_function(params, use_gpu\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m init_params \u001b[39m=\u001b[39m [\u001b[39m2.9644759\u001b[39m , \u001b[39m5.17531829\u001b[39m, \u001b[39m2.70746915\u001b[39m, \u001b[39m0.34326549\u001b[39m, \u001b[39m4.22412149\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m    \u001b[39m5.59371018\u001b[39m, \u001b[39m4.84429238\u001b[39m, \u001b[39m1.80126693\u001b[39m, \u001b[39m4.56341304\u001b[39m, \u001b[39m5.23205335\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m    \u001b[39m5.8469486\u001b[39m , \u001b[39m5.50293912\u001b[39m, \u001b[39m4.16056373\u001b[39m, \u001b[39m2.72112783\u001b[39m, \u001b[39m3.12698443\u001b[39m]  \u001b[39m# random init parameters\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m init_params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(init_params)\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mrequires_grad_()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m _, _, _, loss_hist, time_iters \u001b[39m=\u001b[39m fit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     objective_function, optimizer, init_params,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     return_loss_hist\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_time_iters\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haime/OneDrive/Documents/GitHub/Lagrange%20interpolation%20approach%20for%20GPRX/tqix_compare.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m loss_dict[mode] \u001b[39m=\u001b[39m loss_hist\n",
      "File \u001b[1;32mc:\\Users\\haime\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\cuda\\__init__.py:164\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 164\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    167\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from tqix.pis import *\n",
    "from tqix import *\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cost_function(theta):\n",
    "    qc = tqix.circuit(n)\n",
    "    for i in range(0, n, 3):\n",
    "        qc.RX(thetas[i], 0)\n",
    "        qc.RZ(thetas[i + 1], 1)\n",
    "        qc.RX(thetas[i + 2], 2)\n",
    "\n",
    "    Jx = qc.Jx()\n",
    "    Jy = qc.Jy()\n",
    "    Jz = qc.Jz()\n",
    "\n",
    "    h_LMG = H_LMG(hs[0], lambdax, n, Jx, Jy, Jz)\n",
    "    psi = qc.state\n",
    "    return np.real(np.trace((h_LMG @ psi).toarray()))\n",
    "\n",
    "\n",
    "n = 5\n",
    "loss_dict = {}\n",
    "# function to optimize circuit of sparse array\n",
    "\n",
    "\n",
    "def sparse(optimizer, loss_dict, mode):\n",
    "    def objective_function(params): return cost_function(params)\n",
    "    init_params = [2.9644759 , 5.17531829, 2.70746915, 0.34326549, 4.22412149,\n",
    "       5.59371018, 4.84429238, 1.80126693, 4.56341304, 5.23205335,\n",
    "       5.8469486 , 5.50293912, 4.16056373, 2.72112783, 3.12698443]  # random init parameters\n",
    "    _, _, _, loss_hist, time_iters = fit(\n",
    "        objective_function, optimizer, init_params,\n",
    "        return_loss_hist=True, return_time_iters=True)\n",
    "    loss_dict[mode] = loss_hist\n",
    "    return loss_dict, time_iters\n",
    "# function to optimize circuit of tensor\n",
    "\n",
    "\n",
    "def tensor(optimizer, loss_dict, mode):\n",
    "    objective_function = lambda params: cost_function(params, use_gpu=True)\n",
    "    init_params = [2.9644759 , 5.17531829, 2.70746915, 0.34326549, 4.22412149,\n",
    "       5.59371018, 4.84429238, 1.80126693, 4.56341304, 5.23205335,\n",
    "       5.8469486 , 5.50293912, 4.16056373, 2.72112783, 3.12698443]  # random init parameters\n",
    "    init_params = torch.tensor(init_params).to('cuda').requires_grad_()\n",
    "\n",
    "    _, _, _, loss_hist, time_iters = fit(\n",
    "        objective_function, optimizer, init_params,\n",
    "        return_loss_hist=True, return_time_iters=True)\n",
    "    loss_dict[mode] = loss_hist\n",
    "    return loss_dict, time_iters\n",
    "\n",
    "\n",
    "optimizer = GD(lr=0.0001, eps=1e-10, maxiter=200, tol=1e-19, N=n)\n",
    "loss_dict, _ = tensor(optimizer, loss_dict, \"tensor_gd\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6314cf850edbae231b80224200c9e1580e03453e86236ed42ea1b49b1f8d2e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
